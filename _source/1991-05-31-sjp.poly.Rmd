---
title: |
  Plot polynomials for (generalized) linear regression
rdname: sjp.poly
date: 2015-10-22
output: html_document
layout: article
category: sjplot
images:
FRONTFOMATTER_IMAGES
---

```{r, echo = FALSE, message = FALSE}
library(ggplot2)
library(sjPlot)
```

```{r sjp.poly, cache = TRUE}
library(sjmisc)
data(efc)
# linear fit. loess-smoothed line indicates a more
# or less cubic curve
sjp.poly(efc$c160age, efc$quol_5, 1)

# quadratic fit
sjp.poly(efc$c160age, efc$quol_5, 2)

# linear to cubic fit
sjp.poly(efc$c160age, efc$quol_5,
         1:4, showScatterPlot = FALSE)


library(sjmisc)
data(efc)
# fit sample model
fit <- lm(tot_sc_e ~ c12hour + e17age + e42dep, data = efc)
# inspect relationship between predictors and response
sjp.lm(fit, type = "pred",
       showLoess = TRUE, showScatterPlot = FALSE)
# "e17age" does not seem to be linear correlated to response
# try to find appropiate polynomial. Grey line (loess smoothed)
# indicates best fit. Looks like x^4 has the best fit,
# however, only x^3 has significant p-values.
sjp.poly(fit, "e17age", 2:4, showScatterPlot = FALSE)

## Not run: 
##D # fit new model
##D fit <- lm(tot_sc_e ~ c12hour + e42dep +
##D           e17age + I(e17age^2) + I(e17age^3),
##D           data = efc)
##D # plot marginal effects of polynomial term
##D sjp.lm(fit, type = "poly", poly.term = "e17age")
## End(Not run)



```